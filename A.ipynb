{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "\n",
    "from distribution import AngularCentralGaussian, cholesky_wrapper\n",
    "from pyro.distributions import MultivariateStudentT\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from dataset import H36M\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_mpjpe_batch(points3d, points2d, R, t):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        points3d : (...,J,3)\n",
    "        points2d : (...,V,J,2)\n",
    "        R : (...,V,3,3)\n",
    "        t: (...,V,3,1)\n",
    "    Returns:\n",
    "        weights : (...)\n",
    "    \"\"\"\n",
    "    return torch.exp(\n",
    "        -(\n",
    "            homo_to_eulid(\n",
    "                (R[...,None,:,:] @ points3d[...,None,:,:,None] + t[...,None,:,:]\n",
    "                ).squeeze(-1)\n",
    "            ) - points2d \n",
    "        ).norm(dim=-1).mean((-1,-2))\n",
    "    )\n",
    "\n",
    "\n",
    "class ProbabilisticTriangulation():\n",
    "    def __init__(self, n_batch, n_view):\n",
    "        self.n_batch = n_batch\n",
    "        self.n_view = n_view\n",
    "        self.expect_quan = torch.zeros(self.n_batch,self.n_view-1,4)\n",
    "        self.tril_R = torch.eye(4,4)[None,None].expand(self.n_batch, self.n_view-1,-1,-1)\n",
    "        self.mu_t = torch.zeros(self.n_batch,self.n_view-1,3)\n",
    "        self.tril_t = torch.eye(3,3)[None,None].expand(self.n_batch,self.n_view-1,-1,-1)\n",
    "        #  conv_quan (B,V,4,4)\n",
    "        self.distrR = AngularCentralGaussian(self.tril_R)\n",
    "        #  mu_t (B,V,3) conv_t (B,V,3,3)\n",
    "        self.distrT = MultivariateStudentT(loc=self.mu_t,scale_tril=self.tril_t,df=3)\n",
    "\n",
    "    def sample(self, size : torch.Size()):\n",
    "        self.quan = self.distrR(size)\n",
    "        self.t = self.distrT(size)\n",
    "        # print(self.quan.shape, self.t.shape)\n",
    "\n",
    "        sample_R = torch.cat([torch.eye(3)[None,None,None].expand(size[0],self.n_batch,-1,-1,-1) ,quaternion_to_matrix(self.quan)], dim = -3)\n",
    "        sample_t = torch.cat([torch.zeros(size[0],self.n_batch,1,3) ,self.t] , dim = -2).unsqueeze(-1)\n",
    "        return sample_R, sample_t\n",
    "\n",
    "    def update_paramater_init(self, R,t):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            R : (B,V+1,3,3) -> (B,V,3,3)\n",
    "            t : (B,V+1,3,1) -> (B,V,3,1)\n",
    "        Returns:\n",
    "            sample_quan : (M,B,V,4)\n",
    "            sample_t : (M,B,V,3)\n",
    "            weights: (M,B)\n",
    "            M = 16\n",
    "        \"\"\"\n",
    "        self.sample((15,))\n",
    "        sample_quan = torch.cat([ matrix_to_quaternion(R[:,1:])[None], self.quan ],dim=0)\n",
    "        sample_t = torch.cat([ t[None,:,1:].squeeze(-1), self.t], dim=0)\n",
    "        self.quan = sample_quan\n",
    "        self.t = sample_t\n",
    "        weights = torch.tensor([1]+[0.1 for i in range(15)])[...,None].expand(-1,self.n_batch)\n",
    "        self.update_paramater_with_weights(weights)\n",
    "\n",
    "    def update_paramater_with_weights(self, weights):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            self.quan : (M,B,V,4)\n",
    "            self.t : (M,B,V,3)\n",
    "            weights : (M,B)\n",
    "        Returns:\n",
    "            conv_quan : (B,V,4,4)\n",
    "            mu_t : (B,V,3)\n",
    "            conv_t : (B,V,3,3)\n",
    "        \"\"\"\n",
    "        \n",
    "        # (B,V,4,M) @ (B,V,M,4) -> (B,V,4,4)\n",
    "        conv_quan = (\n",
    "            self.quan.permute(1,2,3,0) @ (self.quan * weights[...,None,None]).permute(1,2,0,3)\n",
    "        ) / weights.sum(0)[...,None,None]\n",
    "        self.tril_quan = cholesky_wrapper(conv_quan)\n",
    "\n",
    "        self.mu_t = self.t.mean(0)\n",
    "\n",
    "        centered_t = self.t - self.mu_t[None]\n",
    "        # (B,V,3,M) @ (B,V,M,3) -> (B,V,3,3)\n",
    "        conv_t = (\n",
    "            centered_t.permute(1,2,3,0) @ (centered_t * weights[...,None,None]).permute(1,2,0,3)\n",
    "        ) / weights.sum(0)[...,None,None]\n",
    "        self.tril_t = cholesky_wrapper(conv_t)\n",
    "\n",
    "        self.expect_quan = (self.quan * weights[...,None,None]).sum(0) / weights.sum(0)[...,None,None]\n",
    "        self.distrR = AngularCentralGaussian(self.tril_quan)\n",
    "        self.distrT = MultivariateStudentT(loc=self.mu_t,scale_tril=self.tril_t,df = 3)\n",
    "\n",
    "    def getRt(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            R : (B,V,3,3)\n",
    "            t : (B,V,3,1)\n",
    "        \"\"\"\n",
    "        R = torch.cat( [ torch.eye(3)[None,None].expand(self.n_batch,1,3,3), quaternion_to_matrix(self.expect_quan) ] ,dim=-3)\n",
    "        t = torch.cat([torch.zeros(self.n_batch,1,3) ,self.mu_t] , dim = -2).unsqueeze(-1)\n",
    "        return R,t\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ProbabilisticTriangulation(1,4)\n",
    "# R,t = a.sample((16,))\n",
    "# weights = cal_mpjpe_batch(pose_3d[None], pose_2d[None], R, t)\n",
    "a.update_paramater_init(Rgt,tgt)\n",
    "R,t = a.getRt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 1.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  1.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  1.0000]],\n",
       " \n",
       "          [[-0.4481, -0.0861, -0.8898],\n",
       "           [-0.0860,  0.9949, -0.0530],\n",
       "           [ 0.8898,  0.0528, -0.4532]],\n",
       " \n",
       "          [[ 0.8750,  0.3302,  0.3541],\n",
       "           [-0.1889,  0.9063, -0.3781],\n",
       "           [-0.4458,  0.2640,  0.8553]],\n",
       " \n",
       "          [[-0.9555,  0.2104,  0.2069],\n",
       "           [ 0.2730,  0.8965,  0.3490],\n",
       "           [-0.1120,  0.3900, -0.9140]]]]),\n",
       " tensor([[[[ 1.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  1.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  1.0000]],\n",
       " \n",
       "          [[-0.6687,  0.1179, -0.7341],\n",
       "           [-0.1866,  0.9291,  0.3192],\n",
       "           [ 0.7197,  0.3505, -0.5993]],\n",
       " \n",
       "          [[ 0.6768, -0.0671,  0.7331],\n",
       "           [ 0.0947,  0.9955,  0.0037],\n",
       "           [-0.7301,  0.0669,  0.6801]],\n",
       " \n",
       "          [[-0.9931, -0.0928, -0.0716],\n",
       "           [-0.1147,  0.8949,  0.4312],\n",
       "           [ 0.0241,  0.4365, -0.8994]]]]))"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R,Rgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalibrationBatch():\n",
    "    def __init__(self, points2d, confi2d):\n",
    "        \"\"\"\n",
    "        points2d : (B,V,J,2)\n",
    "        confi2d : (B,V,J)\n",
    "        points3d : (B,J,3)\n",
    "        confi3d : (B,J)\n",
    "        R : (B,V,3,3)\n",
    "        t : (B,V,3,1)\n",
    "        isdistribution : bool\n",
    "        \"\"\"\n",
    "        self.n_batch,self.n_view,self.n_joint = points2d.shape[:3]\n",
    "        self.points2d = points2d\n",
    "        self.confi2d = confi2d\n",
    "        self.points3d = torch.zeros((self.n_batch,self.n_joint,3))\n",
    "        self.confi3d = torch.zeros((self.n_batch,self.n_joint))\n",
    "        self.R = torch.zeros((self.n_batch,self.n_view,3,3))\n",
    "        self.t = torch.zeros((self.n_batch,self.n_view,3,1))\n",
    "        self.prob_tri = ProbabilisticTriangulation(self.n_batch, self.n_view)\n",
    "\n",
    "\n",
    "    def weighted_triangulation(self, points2d, confi2d, R ,t):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            points2d : (V',J,2)\n",
    "            confi2d : (V',J)\n",
    "            R : (V',3,3)\n",
    "            t : (V',3,1)\n",
    "        Returns:\n",
    "            points3d : (J,3)\n",
    "            confi3d : (J)\n",
    "        \"\"\"\n",
    "        n_view_filter= points2d.shape[0]\n",
    "        points3d = torch.zeros((self.n_joint, 3))\n",
    "        confi3d = torch.zeros((self.n_joint))\n",
    "        # print(points2d.shape,confi2d.shape,R.shape,t.shape)\n",
    "        for j in range(self.n_joint):\n",
    "            A = []\n",
    "            for i in range(n_view_filter):\n",
    "                if confi2d[i,j] > 0.5:\n",
    "                    P = torch.cat([R[i],t[i]],dim=1)\n",
    "                    P3T = P[2]\n",
    "                    A.append(confi2d[i,j] * (points2d[i,j,0]*P3T - P[0]))\n",
    "                    A.append(confi2d[i,j] * (points2d[i,j,1]*P3T - P[1]))\n",
    "            A = torch.stack(A)\n",
    "            # print(A.shape)\n",
    "            if A.shape[0] >= 4:\n",
    "                u, s, vh = torch.linalg.svd(A)\n",
    "                error = s[-1]\n",
    "                X = vh[len(s) - 1]\n",
    "                points3d[j,:] = X[:3] / X[3]\n",
    "                confi3d[j] = np.exp(-torch.abs(error))\n",
    "            else:\n",
    "                points3d[:,j] = torch.tensor([0.0,0.0,0.0])\n",
    "                confi3d[j] = 0\n",
    "\n",
    "        return points3d, confi3d\n",
    "\n",
    "    def weighted_triangulation_sample(self, points2d, confi2d, R ,t):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            points2d : (B,V',J,2)\n",
    "            confi2d : (B,V',J)\n",
    "            R : (M,B, V',3,3)\n",
    "            t : (M,B, V',3,1)\n",
    "        Returns:\n",
    "            sample_points3d : (M,B,J,3)\n",
    "            sample_confi3d : (M,B,J)\n",
    "        \"\"\"\n",
    "        n_sample = R.shape[0]\n",
    "        sample_points3d = torch.zeros((n_sample,self.n_batch,self.n_joint,3))\n",
    "        sample_confi3d = torch.zeros((n_sample,self.n_batch,self.n_joint))\n",
    "        for i in range(n_sample):\n",
    "            for j in range(self.n_batch):\n",
    "                sample_points3d[i,j], sample_confi3d = self.weighted_triangulation(\n",
    "                    points2d[j], confi2d[j], R[i,j], t[i,j]\n",
    "                )\n",
    "        return sample_points3d, sample_confi3d\n",
    "\n",
    "    def pnp(self,batch_id):\n",
    "        for i in range(self.n_view):\n",
    "            mask = torch.logical_and(self.confi2d[batch_id,i]>0.8,self.confi3d[batch_id]>0.8)\n",
    "            p2d = self.points2d[batch_id,i,mask].numpy()\n",
    "            p3d = self.points3d[batch_id,mask].numpy()\n",
    "            ret, rvec, tvec = cv2.solvePnP(p3d, p2d, np.eye(3), np.zeros(5))\n",
    "            R, _ = cv2.Rodrigues(rvec)\n",
    "            self.R[batch_id,i] = torch.tensor(R)\n",
    "            self.t[batch_id,i] = torch.tensor(tvec)\n",
    "\n",
    "\n",
    "    def eight_point(self):\n",
    "        for batch_id in range(self.n_batch):\n",
    "            mask = torch.logical_and(self.confi2d[batch_id,0]>0.8, self.confi2d[batch_id,1]>0.8)\n",
    "            \n",
    "            p0 = self.points2d[batch_id,0,mask].numpy()\n",
    "            p1 = self.points2d[batch_id,1,mask].numpy()\n",
    "            # p0,p1 (N,2)\n",
    "            E, mask = cv2.findEssentialMat(p0, p1, focal=1.0, pp=(0., 0.),\n",
    "                                            method=cv2.RANSAC, prob=0.999, threshold=0.0003)\n",
    "            p0_inliers = p0[mask.ravel() == 1]\n",
    "            p1_inliers = p0[mask.ravel() == 1]\n",
    "            point, R, t,mask  = cv2.recoverPose(E, p0_inliers, p1_inliers)\n",
    "            self.R[batch_id,0],self.t[batch_id,0] = torch.eye(3), torch.zeros((3,1))\n",
    "            self.R[batch_id,1],self.t[batch_id,1] = torch.tensor(R),torch.tensor(t)\n",
    "\n",
    "            print(self.R[batch_id,0],self.t[batch_id,0])\n",
    "\n",
    "            self.points3d[batch_id], self.confi3d[batch_id] = self.weighted_triangulation(\n",
    "                self.points2d[batch_id,:2],self.confi2d[batch_id,:2],self.R[batch_id,:2],self.t[batch_id,:2]\n",
    "            )\n",
    "            \n",
    "            self.pnp(batch_id)\n",
    "            \n",
    "            # print(self.R[batch_id,0],self.t[batch_id,0])\n",
    "            # print(self.mpjpe(2))\n",
    "            # print(self.confi3d[batch_id])\n",
    "\n",
    "            self.points3d[batch_id], self.confi3d[batch_id] = self.weighted_triangulation(\n",
    "                self.points2d[batch_id],self.confi2d[batch_id],self.R[batch_id],self.t[batch_id]\n",
    "            )\n",
    "            # print(self.confi3d[batch_id])\n",
    "            # print(self.mpjpe(self.n_view))\n",
    "\n",
    "    def monte_carlo(self):\n",
    "        self.eight_point()\n",
    "        self.prob_tri.update_paramater_init(self.R,self.t)\n",
    "        for i in range(16):\n",
    "            sample_R, sample_t = self.prob_tri.sample()\n",
    "            sample_points3d, sample_confi3d = self.weighted_triangulation_sample(self.points2d, self.confi2d, sample_R, sample_t)\n",
    "            weights = cal_mpjpe_batch(sample_points3d, self.points2d[None],  sample_R, sample_t)\n",
    "            self.prob_tri.update_paramater_with_weights(weights)\n",
    "            self.R, self.t = self.prob_tri.getRt()\n",
    "\n",
    "    def mpjpe(self, n_view_filter):\n",
    "        return (homo_to_eulid((self.R[...,:n_view_filter,None,:,:] @ self.points3d[...,None,:,:,None] + self.t[...,:n_view_filter,None,:,:]).squeeze(-1)) - self.points2d[:,:n_view_filter] ).mean()\n",
    "    \n",
    "\n",
    "\n",
    "# calibr = CalibrationBatch(pose_2d,confi)\n",
    "# calibr.eight_point()\n",
    "# calibr.mpjpe(2)\n",
    "# calibr.confi2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 17, 2]) torch.Size([1, 17, 3]) torch.Size([1, 4, 17]) torch.Size([1, 4, 3, 3]) torch.Size([1, 4, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "h36m = H36M()\n",
    "h36mloader = DataLoader(h36m, batch_size = 1, shuffle = True)\n",
    "for step, (pose_3d, pose_2d, confi, Rgt, tgt) in enumerate(h36mloader):\n",
    "    print(pose_2d.shape,pose_3d.shape, confi.shape,Rgt.shape,tgt.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]]) tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "tensor([[ 1.0000e+00,  4.3324e-07, -3.1816e-07],\n",
      "        [-4.3324e-07,  1.0000e+00, -1.0566e-06],\n",
      "        [ 3.1816e-07,  1.0566e-06,  1.0000e+00]]) tensor([[1.7213e-07],\n",
      "        [5.0632e-07],\n",
      "        [3.7451e-08]])\n",
      "tensor(-6.9096e-09)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
      "tensor(1.9859e-10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibr = CalibrationBatch(pose_2d,confi)\n",
    "calibr.eight_point()\n",
    "calibr.mpjpe(2)\n",
    "calibr.confi2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quaternions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
