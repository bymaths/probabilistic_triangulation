{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "\n",
    "from distribution import AngularCentralGaussian\n",
    "from pyro.distributions import MultivariateStudentT\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from dataset import H36M\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalibrationBatch():\n",
    "    def __init__(self, points2d, confi2d, is_distr= False):\n",
    "        \"\"\"\n",
    "        points2d : (B,V,J,2)\n",
    "        confi2d : (B,V,J)\n",
    "        points3d : (B,J,3)\n",
    "        confi3d : (B,J)\n",
    "        R : (B,V,3,3)\n",
    "        t : (B,V,3,1)\n",
    "        isdistribution : bool\n",
    "        \"\"\"\n",
    "        self.n_batch,self.n_view,self.n_joint = points2d.shape[:3]\n",
    "        self.points2d = points2d\n",
    "        self.confi2d = confi2d\n",
    "        self.points3d = torch.zeros((self.n_batch,self.n_joint,3))\n",
    "        self.confi3d = torch.zeros((self.n_batch,self.n_joint))\n",
    "        self.R = torch.zeros((self.n_batch,self.n_view,3,3))\n",
    "        self.t = torch.zeros((self.n_batch,self.n_view,3,1))\n",
    "        self.is_distribution = is_distribution\n",
    "        if is_distr:\n",
    "            self.distrR = AngularCentralGaussian(torch.eye(4,4)[None,None].expand(self.n_batch, self.n_view-1,-1,-1))\n",
    "            self.distrT = MultivariateStudentT(loc=torch.zeros(self.n_batch,self.view-1,3),scale_tril=torch.eye(3,3)[None,None](self.n_batch,self.view-1,-1,-1),df=3)\n",
    "\n",
    "    def weighted_triangulation(self, points2d, confi2d, R ,t):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            points2d : (V',J,2)\n",
    "            confi2d : (V',J)\n",
    "            R : (V',3,3)\n",
    "            t : (V',3,1)\n",
    "        Returns:\n",
    "            points3d : (J,3)\n",
    "            confi3d : (J)\n",
    "        \"\"\"\n",
    "        n_view_filter= points2d.shape[0]\n",
    "        points3d = torch.zeros((self.n_joint, 3))\n",
    "        confi3d = torch.zeros((self.n_joint))\n",
    "        # print(points2d.shape,confi2d.shape,R.shape,t.shape)\n",
    "        for j in range(self.n_joint):\n",
    "            A = []\n",
    "            for i in range(n_view_filter):\n",
    "                if confi2d[i,j] > 0.5:\n",
    "                    P = torch.cat([R[i],t[i]],dim=1)\n",
    "                    P3T = P[2]\n",
    "                    A.append(confi2d[i,j] * (points2d[i,j,0]*P3T - P[0]))\n",
    "                    A.append(confi2d[i,j] * (points2d[i,j,1]*P3T - P[1]))\n",
    "            A = torch.stack(A)\n",
    "            # print(A.shape)\n",
    "            if A.shape[0] >= 4:\n",
    "                u, s, vh = torch.linalg.svd(A)\n",
    "                error = s[-1]\n",
    "                X = vh[len(s) - 1]\n",
    "                points3d[j,:] = X[:3] / X[3]\n",
    "                confi3d[j] = np.exp(-torch.abs(error))\n",
    "            else:\n",
    "                points3d[:,j] = torch.tensor([0.0,0.0,0.0])\n",
    "                confi3d[j] = 0\n",
    "\n",
    "        return points3d, confi3d\n",
    "\n",
    "    def pnp(self,batch_id):\n",
    "        for i in range(self.n_view):\n",
    "            mask = torch.logical_and(self.confi2d[batch_id,i]>0.8,self.confi3d[batch_id]>0.8)\n",
    "            p2d = self.points2d[batch_id,i,mask].numpy()\n",
    "            p3d = self.points3d[batch_id,mask].numpy()\n",
    "            ret, rvec, tvec = cv2.solvePnP(p3d, p2d, np.eye(3), np.zeros(5))\n",
    "            R, _ = cv2.Rodrigues(rvec)\n",
    "            self.R[batch_id,i] = torch.tensor(R)\n",
    "            self.t[batch_id,i] = torch.tensor(tvec)\n",
    "\n",
    "\n",
    "    def eight_point(self):\n",
    "        for batch_id in range(self.n_batch):\n",
    "            mask = torch.logical_and(self.confi2d[batch_id,0]>0.8, self.confi2d[batch_id,1]>0.8)\n",
    "            \n",
    "            p0 = self.points2d[batch_id,0,mask].numpy()\n",
    "            p1 = self.points2d[batch_id,1,mask].numpy()\n",
    "            # p0,p1 (N,2)\n",
    "            E, mask = cv2.findEssentialMat(p0, p1, focal=1.0, pp=(0., 0.),\n",
    "                                            method=cv2.RANSAC, prob=0.999, threshold=0.0003)\n",
    "            p0_inliers = p0[mask.ravel() == 1]\n",
    "            p1_inliers = p0[mask.ravel() == 1]\n",
    "            point, R, t,mask  = cv2.recoverPose(E, p0_inliers, p1_inliers)\n",
    "            self.R[batch_id,0],self.t[batch_id,0] = torch.eye(3), torch.zeros((3,1))\n",
    "            self.R[batch_id,1],self.t[batch_id,1] = torch.tensor(R),torch.tensor(t)\n",
    "\n",
    "            print(self.R[batch_id,0],self.t[batch_id,0])\n",
    "\n",
    "            self.points3d[batch_id], self.confi3d[batch_id] = self.weighted_triangulation(\n",
    "                self.points2d[batch_id,:2],self.confi2d[batch_id,:2],self.R[batch_id,:2],self.t[batch_id,:2]\n",
    "            )\n",
    "            \n",
    "            self.pnp(batch_id)\n",
    "            \n",
    "            print(self.R[batch_id,0],self.t[batch_id,0])\n",
    "            print(self.mpjpe(2))\n",
    "            print(self.confi3d[batch_id])\n",
    "\n",
    "            self.points3d[batch_id], self.confi3d[batch_id] = self.weighted_triangulation(\n",
    "                self.points2d[batch_id],self.confi2d[batch_id],self.R[batch_id],self.t[batch_id]\n",
    "            )\n",
    "            print(self.confi3d[batch_id])\n",
    "            print(self.mpjpe(self.n_view))\n",
    "\n",
    "\n",
    "\n",
    "    def mpjpe(self, n_view_filter):\n",
    "        return (homo_to_eulid((self.R[...,:n_view_filter,None,:,:] @ self.points3d[...,None,:,:,None] + self.t[...,:n_view_filter,None,:,:]).squeeze(-1)) - self.points2d[:,:n_view_filter] ).mean()\n",
    "    \n",
    "\n",
    "\n",
    "# calibr = CalibrationBatch(pose_2d,confi)\n",
    "# calibr.eight_point()\n",
    "# calibr.mpjpe(2)\n",
    "# calibr.confi2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 17, 2]) torch.Size([1, 17, 3]) torch.Size([1, 4, 17]) torch.Size([1, 4, 3, 3]) torch.Size([1, 4, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "h36m = H36M()\n",
    "h36mloader = DataLoader(h36m, batch_size = 1, shuffle = True)\n",
    "for step, (pose_3d, pose_2d, confi, R, t) in enumerate(h36mloader):\n",
    "    print(pose_2d.shape,pose_3d.shape, confi.shape,R.shape,t.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]]) tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "tensor([[ 1.0000e+00,  4.3324e-07, -3.1816e-07],\n",
      "        [-4.3324e-07,  1.0000e+00, -1.0566e-06],\n",
      "        [ 3.1816e-07,  1.0566e-06,  1.0000e+00]]) tensor([[1.7213e-07],\n",
      "        [5.0632e-07],\n",
      "        [3.7451e-08]])\n",
      "tensor(-6.9096e-09)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
      "tensor(1.9859e-10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibr = CalibrationBatch(pose_2d,confi)\n",
    "calibr.eight_point()\n",
    "calibr.mpjpe(2)\n",
    "calibr.confi2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
